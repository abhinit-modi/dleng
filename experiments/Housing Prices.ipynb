{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from __future__ import absolute_import, division, print_function, unicode_literals\n\n# System\nimport math\nimport os\nimport sys\n\n# Data\nimport numpy as np\nimport pandas as pd\n\n# Plot\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom IPython.display import clear_output\n\n# Util\nfrom six.moves import urllib\nfrom sklearn.model_selection import train_test_split\n\n# MachineLearning\ntry:\n  # %tensorflow_version only exists in Colab.\n    %tensorflow_version 2.x\nexcept Exception:\n    pass\nimport tensorflow.compat.v2.feature_column as fc\n\nimport tensorflow as tf\n\nfrom tensorflow import feature_column\nfrom tensorflow.keras import layers\n\ntf.compat.v1.enable_eager_execution()\n\npd.options.display.float_format = '{:.2f}'.format\npd.options.display.max_rows = 15\n\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_data = pd.read_csv('/kaggle/input/home-data-for-ml-course/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = pd.read_csv('/kaggle/input/home-data-for-ml-course/test.csv')\ntest_data.info()\ntest_data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.info()\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.describe()\ntrain_data.describe(include=['O'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['MSSubClass'] = train_data['MSSubClass'].apply(int)\ntrain_data['OverallQual'] = train_data['OverallQual'].apply(int)\ntrain_data['OverallCond'] = train_data['OverallCond'].apply(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label = 'SalePrice'\nnumeric_cols = list(set(train_data.describe().columns) - set([label]))\ncategorical_cols = list(set(train_data.columns) - set(numeric_cols) - set([label]))\nprint(len(numeric_cols))\nprint(len(categorical_cols))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"colormap = plt.cm.RdBu\nplt.figure(figsize=(70,60))\nplt.title('Pearson Correlation of Features', y=1.05, size=15)\nsns.heatmap(train_data[numeric_cols + [label]].astype(float).corr(),linewidths=0.1,vmax=1.0, \n            square=True, cmap=colormap, linecolor='white', annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = pd.DataFrame(abs(train_data.corr()[label]).sort_values(ascending = False))\n\nx = x[x[label] >= 0.45]\n\nx.index\n\nfeatures = list(set(x.index) - set(['GarageYrBlt', 'MasVnrArea']))\n\nfeatures","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data[features].info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(categorical_cols)\n\ntrain_data[['BsmtQual']].describe(include=[\"O\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data[[label]].plot.hist(bins=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in categorical_cols[0:1]:\n    print(col)\n    for value in train_data[col].unique():\n        df = train_data[train_data[col] == value][label]\n        df.plot.hist(subplots=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(categorical_cols)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fname = \"BsmtQual\"\n\ntrain_data[[label]].plot.hist(bins=20)\ntrain_data[[fname]].describe(include=[\"O\"])\npal = {1:\"seagreen\", 0:\"gray\"}\ng = sns.FacetGrid(train_data,size=5, col=fname, margin_titles=True,\n                  palette=pal)\ng = g.map(plt.hist, \"SalePrice\", edgecolor = 'white', bins=20);\ng.fig.suptitle(\"SalePrice and \" + fname, size = 25)\nplt.subplots_adjust(top=0.90)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data[[\"OverallQual\", label]].groupby(\"OverallQual\", as_index=False).mean().sort_values(by=label)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"------------------------------------------------------------------------------------"},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in ['FullBath', 'TotRmsAbvGrd', 'Fireplaces', 'GarageCars', 'OverallQual']:\n    train_data[feature] = train_data[feature].apply(str)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NUMERIC_COLUMNS = ['1stFlrSF', 'GarageArea', 'GrLivArea', 'TotalBsmtSF', 'YearBuilt', 'YearRemodAdd']\nCATEGORICAL_COLUMNS = ['Neighborhood', 'ExterQual', 'HouseStyle', 'SaleCondition', 'KitchenQual', 'CentralAir', 'FullBath', 'TotRmsAbvGrd', 'Fireplaces', 'GarageCars', 'OverallQual']\n# LABEL = 'SalePrice'\n\n# NUMERIC_COLUMNS = ['1stFlrSF', 'GrLivArea', 'YearBuilt']\n# CATEGORICAL_COLUMNS = ['SaleCondition', 'Neighborhood', 'FullBath', 'TotRmsAbvGrd', 'GarageCars', 'OverallQual']\nLABEL = 'SalePrice'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# maxi = train_data[label].max()\n# mini = train_data[label].min()\nfor feature in NUMERIC_COLUMNS:\n    train_data[feature] = train_data[feature].apply(lambda x : np.log(x+1))\ntrain_data[label] = np.log(train_data[label])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dftrain, dfeval = train_test_split(train_data[CATEGORICAL_COLUMNS + NUMERIC_COLUMNS + [LABEL]], test_size=0.3)\n\nytrain = dftrain.pop(LABEL)\nyeval = dfeval.pop(LABEL)\n\ndftrain.info()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_columns = []\ncategorical_feature_columns = []\ncrossed_feature_columns = []\nnumeric_feature_columns = []\n\nfor feature_name in CATEGORICAL_COLUMNS:\n    vocabulary = dftrain[feature_name].unique()\n    categorical_feature_columns.append(\n        feature_column.indicator_column(\n            tf.feature_column.categorical_column_with_vocabulary_list(\n                feature_name, \n                vocabulary\n            )\n        )\n    )\n\nepsilon = 0.1\n\nfor feature_name in NUMERIC_COLUMNS:\n    numeric_feature_columns.append(\n        tf.feature_column.numeric_column(\n            feature_name, \n            dtype=tf.float32,\n#             normalizer_fn=lambda val: (val - dftrain.mean()[feature_name]) / (epsilon + dftrain.std()[feature_name])\n#             normalizer_fn=lambda val: np.log(val)\n        )\n    )\n    \n# crossed_feature = feature_column.crossed_column([tf.feature_column.categorical_column_with_vocabulary_list(\n#                 'SibSp', \n#                 vocabulary\n#             ), tf.feature_column.categorical_column_with_vocabulary_list(\n#                 'Parch', \n#                 vocabulary\n#             )], hash_bucket_size=15)\n# crossed_feature = feature_column.indicator_column(crossed_feature)\n# crossed_feature_columns.append(crossed_feature)\n\n# age_buckets = feature_column.bucketized_column(tf.feature_column.numeric_column(\n#             feature_name, \n#             dtype=tf.float32,\n#             normalizer_fn=lambda val: (val - dftrain.mean()[feature_name]) / (epsilon + dftrain.std()[feature_name])\n#         ), boundaries=[5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70])\n\n# feature_columns.append(age_buckets)\nfeature_columns.extend(categorical_feature_columns) \n# feature_columns.extend(crossed_feature_columns)\nfeature_columns.extend(numeric_feature_columns)\nprint(len(feature_columns))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Config\nBATCH_SIZE = 32\nNUM_EPOCHS = 50\n\nNUM_TRAINING_STEPS = 100\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# InputFunctors\ndef df_to_dataset(data_df, label_df, num_epochs=10, shuffle=True, batch_size=32):\n    ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))\n    # Dataset needs to be re-assigned\n    if shuffle:\n        ds = ds.shuffle(1000)\n    ds = ds.batch(batch_size).repeat(num_epochs)\n    return ds\n\ndef testdf_to_dataset(data_df, num_epochs=10, batch_size=32):\n    ds = tf.data.Dataset.from_tensor_slices(dict(data_df))\n    # Dataset needs to be re-assigned\n    ds = ds.batch(batch_size).repeat(num_epochs)\n    return ds\n\ntrain_ds = df_to_dataset(dftrain, ytrain, num_epochs=NUM_EPOCHS, shuffle=True, batch_size=BATCH_SIZE)\neval_ds = df_to_dataset(dfeval, yeval, num_epochs=1, shuffle=False, batch_size=BATCH_SIZE)\n# test_ds = testdf_to_dataset(test_data, num_epochs=1, batch_size=BATCH_SIZE)\n\nds = df_to_dataset(dftrain, ytrain, batch_size=5)\nfor feature_batch, label_batch in ds.take(1):\n    print('Length of batch: ', len(label_batch))\n    print('Number of features: ', len(feature_batch))\n    print('Some feature keys:', list(feature_batch.keys()))\n    print('A batch of Labels:', label_batch.numpy())\n    print()\n\n# InspectInput of model\ndef demo(example_batch, feature_column):\n    feature_layer = layers.DenseFeatures(feature_column)\n    print(feature_layer(example_batch).numpy())\n\nexample_batch = next(iter(ds))[0]\ndemo(example_batch, feature_columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_input_fn(data_df, label_df, n_epochs=None, shuffle=True, batch_size=32):\n    def input_fn():\n        return df_to_dataset(data_df, label_df, n_epochs, shuffle, batch_size)\n    return input_fn\n\ndef make_test_input_fn(data_df, n_epochs=None, batch_size=32):\n    def input_fn():\n        return testdf_to_dataset(data_df, n_epochs, batch_size)\n    return input_fn\n\ntrain_input_fn = make_input_fn(dftrain, ytrain, n_epochs=NUM_EPOCHS, shuffle=True, batch_size=BATCH_SIZE)\neval_input_fn = make_input_fn(dfeval, yeval, n_epochs=1, shuffle=False, batch_size=BATCH_SIZE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"linear_est = tf.estimator.LinearRegressor(\n    feature_columns=feature_columns,\n    optimizer=tf.keras.optimizers.SGD(learning_rate=0.001))\nlinear_est.train(train_input_fn, steps=10000)\nscores = linear_est.evaluate(eval_input_fn)\nprint('scores', scores)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in ['FullBath', 'TotRmsAbvGrd', 'Fireplaces', 'GarageCars', 'OverallQual']:\n    test_data[feature] = test_data[feature].apply(str)\n\nfor feature in NUMERIC_COLUMNS:\n    test_data[feature] = test_data[feature].apply(lambda x : np.log(x+1))\n\n# test_ds = testdf_to_dataset(test_data[NUMERIC_COLUMNS + CATEGORICAL_COLUMNS], num_epochs=1, batch_size=BATCH_SIZE)\ntest_input_fn = make_test_input_fn(test_data[NUMERIC_COLUMNS + CATEGORICAL_COLUMNS], n_epochs=1, batch_size=BATCH_SIZE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"yeval.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = linear_est.predict(test_input_fn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for item in predictions:\n    print(np.exp(item['predictions'][0]))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}